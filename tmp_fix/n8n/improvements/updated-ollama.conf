# Upstream definition for Ollama
upstream ollama_backend {
    # Primary server - Docker container name
    server ollama-cpu:11434;
    
    # Keepalive connections
    keepalive 32;
}

# Ollama Server Block
server {
    listen 80;
    listen [::]:80;
    listen 443 ssl;
    listen [::]:443 ssl;
    http2 on;
    server_name ollama.mulder.local;

    # Service unavailable page
    error_page 502 503 504 = @maintenance;
    
    # Maintenance location
    location @maintenance {
        root /home/groot/nginx/html;
        try_files /maintenance.html /50x.html =502;
        internal;
    }

    ssl_certificate /home/groot/nginx/certs/nginx.crt;
    ssl_certificate_key /home/groot/nginx/certs/nginx.key;

    access_log /var/log/nginx/ollama-access.log;
    error_log /var/log/nginx/ollama-error.log notice;

    # Security headers
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;

    # Health check endpoint
    location /health {
        proxy_pass http://ollama_backend/health;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        access_log off;
    }

    # API version endpoint - Added based on AI's configuration
    location /api/version {
        proxy_pass http://ollama_backend/api/version;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # API tags endpoint - Added based on AI's configuration
    location /api/tags {
        proxy_pass http://ollama_backend/api/tags;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    location / {
        # Enable error interception
        proxy_intercept_errors on;

        # Proxy settings
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_set_header X-Forwarded-Host $host;
        proxy_set_header X-Forwarded-Port $server_port;

        # WebSocket support
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";

        # Security
        proxy_hide_header X-Powered-By;
        proxy_hide_header Server;

        # Pass to upstream without protocol prefix (FIXED by AI)
        proxy_pass http://ollama_backend;
        
        # Extended timeouts for LLM operations
        proxy_read_timeout 600s;
        proxy_send_timeout 600s;
        proxy_connect_timeout 600s;
        
        # Increase buffer sizes for large responses
        proxy_buffer_size 16k;
        proxy_buffers 8 16k;
        proxy_busy_buffers_size 32k;
    }
} 